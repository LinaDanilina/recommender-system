{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "deep ctr.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinaDanilina/recommender-system/blob/master/deep_ctr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUUlsrfAGISA",
        "colab_type": "text"
      },
      "source": [
        "# Deep CTR (Attention and Self-attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RozPARxzGKrl",
        "colab_type": "code",
        "outputId": "ef53e10b-2a07-4820-f7d4-e8f31ccde049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osfqavLTGUQw",
        "colab_type": "code",
        "outputId": "04fb75a9-3900-42bc-c55f-8746f3002144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "! ls\n",
        "%cd drive/My Drive/DeepCTR-Torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n",
            "/content/drive/My Drive/DeepCTR-Torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le6x327NGISC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from deepctr_torch.models import DeepFM\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    explained_variance_score,\n",
        "    roc_auc_score,\n",
        "    log_loss,\n",
        "    ndcg_score\n",
        ")\n",
        "import sklearn\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeRpie3TGISH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d4303b36-4841-4321-9dc0-6dc9a3e8c76c"
      },
      "source": [
        "# pass in column names for each CSV\n",
        "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('u.user', sep='|', names=u_cols)\n",
        "\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv('u.data', sep='\\t', names=r_cols)\n",
        "\n",
        "# the movies file contains columns indicating the movie's genres\n",
        "# let's only load the first five columns of the file with usecols\n",
        "m_cols = ['movie_id', 'title', 'release_date', 'imdb_url']\n",
        "movies = pd.read_csv('u.item', sep='|', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', \n",
        "                                                  'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
        "                                                  'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "                                                  'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'],\n",
        "                     dtype={'release_date': \"S100\", 'imdb_url': \"S200\"},encoding = \"ISO-8859-1\")\n",
        "genres = ['unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
        "          'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "          'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "movies['genre'] = movies[genres].idxmax(1)\n",
        "#movies = movies.drop(genres, axis=1)\n",
        "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
        "movies['genre'] = genres_encoder.fit_transform(\n",
        "        movies['genre'].apply(lambda s: s.split(\"|\"))\n",
        "    ).tolist()\n",
        "    \n",
        "# create one merged DataFrame\n",
        "movie_ratings = pd.merge(movies[['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL','genre']], ratings)\n",
        "#data = pd.merge(movie_ratings, users)\n",
        "data=pd.read_csv('data.csv')\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>release_date</th>\n",
              "      <th>video_release_date</th>\n",
              "      <th>IMDb_URL</th>\n",
              "      <th>genre</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>unix_timestamp</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>308</td>\n",
              "      <td>4</td>\n",
              "      <td>887736532</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>retired</td>\n",
              "      <td>95076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>308</td>\n",
              "      <td>5</td>\n",
              "      <td>887737890</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>retired</td>\n",
              "      <td>95076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>308</td>\n",
              "      <td>4</td>\n",
              "      <td>887739608</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>retired</td>\n",
              "      <td>95076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Twelve Monkeys (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>308</td>\n",
              "      <td>4</td>\n",
              "      <td>887738847</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>retired</td>\n",
              "      <td>95076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>Babe (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>308</td>\n",
              "      <td>5</td>\n",
              "      <td>887736696</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>retired</td>\n",
              "      <td>95076</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  movie_id            movie_title  ... sex  occupation zip_code\n",
              "0           0         1       Toy Story (1995)  ...   M     retired    95076\n",
              "1           1         4      Get Shorty (1995)  ...   M     retired    95076\n",
              "2           2         5         Copycat (1995)  ...   M     retired    95076\n",
              "3           3         7  Twelve Monkeys (1995)  ...   M     retired    95076\n",
              "4           4         8            Babe (1995)  ...   M     retired    95076\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F4KWDAaGGISP",
        "colab_type": "code",
        "outputId": "ed83551f-a924-4d84-f5b5-5436595138d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
        "from deepctr_torch.models import DeepFM\n",
        "\n",
        "sparse_features = [\"movie_id\", \"user_id\",\n",
        "                       \"sex\", \"age\", \"occupation\", \"zip_code\"]\n",
        "target = ['rating']\n",
        "\n",
        "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feat] = lbe.fit_transform(data[feat])\n",
        "    # 2.count #unique features for each sparse field\n",
        "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
        "                              for feat in sparse_features]\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 3.generate input data for model\n",
        "\n",
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "train_model_input = {name: train[name] for name in feature_names}\n",
        "test_model_input = {name: test[name] for name in feature_names}\n",
        "    # 4.Define Model,train,predict and evaluate\n",
        "\n",
        "device = 'cpu'\n",
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    print('cuda ready...')\n",
        "    device = 'cuda:0'\n",
        "\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "start_time = time.time()\n",
        "history = model.fit(train_model_input, train[target].values,\n",
        "                        batch_size=256, epochs=50, verbose=2, validation_split=0.2)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "test_time = time.time() - start_time\n",
        "\n",
        "rmse=math.sqrt(round(mean_squared_error(test[target].values, pred_ans), 4))\n",
        "print(\"test RMSE\",rmse )\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 60000 samples, validate on 15000 samples, 235 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.0802 - mse:  2.0767 - val_mse:  0.9362\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8800 - mse:  0.8801 - val_mse:  0.9215\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8602 - mse:  0.8601 - val_mse:  0.9081\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8546 - mse:  0.8552 - val_mse:  0.9088\n",
            "Epoch 5/50\n",
            "3s - loss:  0.8510 - mse:  0.8513 - val_mse:  0.9163\n",
            "Epoch 6/50\n",
            "3s - loss:  0.8491 - mse:  0.8496 - val_mse:  0.9088\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8473 - mse:  0.8469 - val_mse:  0.9130\n",
            "Epoch 8/50\n",
            "3s - loss:  0.8468 - mse:  0.8467 - val_mse:  0.9150\n",
            "Epoch 9/50\n",
            "3s - loss:  0.8456 - mse:  0.8463 - val_mse:  0.9115\n",
            "Epoch 10/50\n",
            "3s - loss:  0.8447 - mse:  0.8452 - val_mse:  0.9079\n",
            "Epoch 11/50\n",
            "3s - loss:  0.8434 - mse:  0.8435 - val_mse:  0.9096\n",
            "Epoch 12/50\n",
            "3s - loss:  0.8431 - mse:  0.8432 - val_mse:  0.9082\n",
            "Epoch 13/50\n",
            "3s - loss:  0.8405 - mse:  0.8404 - val_mse:  0.9070\n",
            "Epoch 14/50\n",
            "3s - loss:  0.8416 - mse:  0.8420 - val_mse:  0.9153\n",
            "Epoch 15/50\n",
            "3s - loss:  0.8431 - mse:  0.8426 - val_mse:  0.9075\n",
            "Epoch 16/50\n",
            "3s - loss:  0.8388 - mse:  0.8388 - val_mse:  0.9071\n",
            "Epoch 17/50\n",
            "3s - loss:  0.8393 - mse:  0.8390 - val_mse:  0.9098\n",
            "Epoch 18/50\n",
            "3s - loss:  0.8412 - mse:  0.8411 - val_mse:  0.9162\n",
            "Epoch 19/50\n",
            "3s - loss:  0.8377 - mse:  0.8382 - val_mse:  0.9119\n",
            "Epoch 20/50\n",
            "3s - loss:  0.8388 - mse:  0.8383 - val_mse:  0.9140\n",
            "Epoch 21/50\n",
            "3s - loss:  0.8358 - mse:  0.8357 - val_mse:  0.9082\n",
            "Epoch 22/50\n",
            "3s - loss:  0.8349 - mse:  0.8352 - val_mse:  0.9091\n",
            "Epoch 23/50\n",
            "3s - loss:  0.8331 - mse:  0.8333 - val_mse:  0.9078\n",
            "Epoch 24/50\n",
            "3s - loss:  0.8319 - mse:  0.8323 - val_mse:  0.9061\n",
            "Epoch 25/50\n",
            "3s - loss:  0.8289 - mse:  0.8290 - val_mse:  0.8989\n",
            "Epoch 26/50\n",
            "3s - loss:  0.8237 - mse:  0.8236 - val_mse:  0.8995\n",
            "Epoch 27/50\n",
            "3s - loss:  0.8185 - mse:  0.8187 - val_mse:  0.8936\n",
            "Epoch 28/50\n",
            "3s - loss:  0.8150 - mse:  0.8151 - val_mse:  0.8954\n",
            "Epoch 29/50\n",
            "3s - loss:  0.8111 - mse:  0.8113 - val_mse:  0.8911\n",
            "Epoch 30/50\n",
            "3s - loss:  0.8096 - mse:  0.8091 - val_mse:  0.8953\n",
            "Epoch 31/50\n",
            "3s - loss:  0.8070 - mse:  0.8068 - val_mse:  0.9088\n",
            "Epoch 32/50\n",
            "3s - loss:  0.8064 - mse:  0.8065 - val_mse:  0.8907\n",
            "Epoch 33/50\n",
            "3s - loss:  0.8026 - mse:  0.8028 - val_mse:  0.9024\n",
            "Epoch 34/50\n",
            "3s - loss:  0.8016 - mse:  0.8026 - val_mse:  0.9013\n",
            "Epoch 35/50\n",
            "3s - loss:  0.8000 - mse:  0.7999 - val_mse:  0.8930\n",
            "Epoch 36/50\n",
            "3s - loss:  0.7976 - mse:  0.7970 - val_mse:  0.8939\n",
            "Epoch 37/50\n",
            "3s - loss:  0.7963 - mse:  0.7961 - val_mse:  0.8982\n",
            "Epoch 38/50\n",
            "3s - loss:  0.7957 - mse:  0.7952 - val_mse:  0.9025\n",
            "Epoch 39/50\n",
            "3s - loss:  0.7936 - mse:  0.7937 - val_mse:  0.8905\n",
            "Epoch 40/50\n",
            "3s - loss:  0.7909 - mse:  0.7907 - val_mse:  0.8896\n",
            "Epoch 41/50\n",
            "3s - loss:  0.7907 - mse:  0.7905 - val_mse:  0.8885\n",
            "Epoch 42/50\n",
            "3s - loss:  0.7867 - mse:  0.7862 - val_mse:  0.8942\n",
            "Epoch 43/50\n",
            "3s - loss:  0.7858 - mse:  0.7856 - val_mse:  0.8916\n",
            "Epoch 44/50\n",
            "3s - loss:  0.7834 - mse:  0.7833 - val_mse:  0.8959\n",
            "Epoch 45/50\n",
            "3s - loss:  0.7823 - mse:  0.7821 - val_mse:  0.8970\n",
            "Epoch 46/50\n",
            "3s - loss:  0.7801 - mse:  0.7801 - val_mse:  0.8949\n",
            "Epoch 47/50\n",
            "3s - loss:  0.7782 - mse:  0.7788 - val_mse:  0.8976\n",
            "Epoch 48/50\n",
            "3s - loss:  0.7762 - mse:  0.7760 - val_mse:  0.8934\n",
            "Epoch 49/50\n",
            "3s - loss:  0.7742 - mse:  0.7743 - val_mse:  0.8957\n",
            "Epoch 50/50\n",
            "3s - loss:  0.7743 - mse:  0.7743 - val_mse:  0.8935\n",
            "test RMSE 0.9450396817065408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5QvPAw4GISh",
        "colab_type": "code",
        "outputId": "644d8964-c6ee-44fa-9527-3848b108a601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "def metrics(data_true, data_pred,time_train, time_test):\n",
        "    mse=np.sqrt(mean_squared_error(data_true, data_pred))\n",
        "    mae=mean_absolute_error(data_true, data_pred)\n",
        "    r2=r2_score(data_true, data_pred)\n",
        "    ex_var=explained_variance_score(data_true, data_pred)\n",
        "    df=pd.DataFrame({\"RMSE\": mse, \"MAE\":mae, \"R2_score\":r2, \"explained variance\":ex_var, 'train time':time_train,\n",
        "                     'test time':time_test},index=[0])\n",
        "    return df\n",
        "\n",
        "metrics(test[target].values, pred_ans,train_time, test_time)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R2_score</th>\n",
              "      <th>explained variance</th>\n",
              "      <th>train time</th>\n",
              "      <th>test time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.945033</td>\n",
              "      <td>0.742185</td>\n",
              "      <td>0.299992</td>\n",
              "      <td>0.300253</td>\n",
              "      <td>168.467277</td>\n",
              "      <td>0.238441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       RMSE       MAE  R2_score  explained variance  train time  test time\n",
              "0  0.945033  0.742185  0.299992            0.300253  168.467277   0.238441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lSKIIfyBzCx",
        "colab_type": "code",
        "outputId": "981f0336-ea02-436f-936b-e2161bdd095b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "ndcg_score(test[target].values, pred_ans)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e0f052c8eb44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndcg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mndcg_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     \u001b[0m_check_dcg_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ndcg_sample_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_ties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_ties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_check_dcg_target_type\u001b[0;34m(y_true)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         raise ValueError(\n\u001b[1;32m   1162\u001b[0m             \"Only {} formats are supported. Got {} instead\".format(\n\u001b[0;32m-> 1163\u001b[0;31m                 supported_fmt, y_type))\n\u001b[0m\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only ('multilabel-indicator', 'continuous-multioutput', 'multiclass-multioutput') formats are supported. Got multiclass instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmNsoVB2x8sw",
        "colab_type": "code",
        "outputId": "30807e0d-d75a-4431-8914-4b055918db59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(test[target].values, pred_ans)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dbc53a06e657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmCvDc1v0Jht",
        "colab_type": "code",
        "outputId": "5c9220f7-3be0-4e41-8864-1417b2845479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(test[target].values, pred_ans)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dd4a0f552d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc9x44XBGISk",
        "colab_type": "text"
      },
      "source": [
        "___________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-e79TjGISk",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqCnkdYPGISl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## -*- coding: utf-8 -*-\n",
        "\n",
        "#ratings-u.data df\n",
        "#movies-u.item movie_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq_WLL3fGISn",
        "colab_type": "code",
        "outputId": "60203b6f-bee0-406c-fcec-75397e85f715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>release_date</th>\n",
              "      <th>video_release_date</th>\n",
              "      <th>IMDb_URL</th>\n",
              "      <th>genre</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>unix_timestamp</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>307</td>\n",
              "      <td>4</td>\n",
              "      <td>887736532</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>307</td>\n",
              "      <td>5</td>\n",
              "      <td>887737890</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>307</td>\n",
              "      <td>4</td>\n",
              "      <td>887739608</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Twelve Monkeys (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>307</td>\n",
              "      <td>4</td>\n",
              "      <td>887738847</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>Babe (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>307</td>\n",
              "      <td>5</td>\n",
              "      <td>887736696</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  movie_id            movie_title  ... sex  occupation zip_code\n",
              "0           0         0       Toy Story (1995)  ...   1          15      716\n",
              "1           1         3      Get Shorty (1995)  ...   1          15      716\n",
              "2           2         4         Copycat (1995)  ...   1          15      716\n",
              "3           3         6  Twelve Monkeys (1995)  ...   1          15      716\n",
              "4           4         7            Babe (1995)  ...   1          15      716\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URRrFCoIGISr",
        "colab_type": "code",
        "outputId": "f87bdb08-0c99-40f0-ba33-cd222ff2d0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# capture all genre columns, get them to one column, remove them after it is done\n",
        "genres = ['unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
        "          'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "          'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "movies['genre'] = movies[genres].idxmax(1)\n",
        "movies = movies.drop(genres, axis=1)\n",
        "movies.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>release_date</th>\n",
              "      <th>video_release_date</th>\n",
              "      <th>IMDb_URL</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>Animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>Crime</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie_id  ...      genre\n",
              "0         1  ...  Animation\n",
              "1         2  ...     Action\n",
              "2         3  ...   Thriller\n",
              "3         4  ...     Action\n",
              "4         5  ...      Crime\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4oa49rfGISv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = movies[['movie_id', 'movie_title', 'release_date', 'IMDb_URL', 'genre']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auMI1wkdGISz",
        "colab_type": "code",
        "outputId": "1b4b052f-ae25-4214-b919-3f1f7664d214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "movies.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>release_date</th>\n",
              "      <th>IMDb_URL</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>Animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>b'01-Jan-1995'</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>Crime</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie_id  ...      genre\n",
              "0         1  ...  Animation\n",
              "1         2  ...     Action\n",
              "2         3  ...   Thriller\n",
              "3         4  ...     Action\n",
              "4         5  ...      Crime\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivO7GgjFGIS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users_items_matrix_df=pd.read_csv('rating.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YriPATswGIS7",
        "colab_type": "code",
        "outputId": "99149b97-8259-4129-c736-4deb81b929af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "users_items_matrix_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1643</th>\n",
              "      <th>1644</th>\n",
              "      <th>1645</th>\n",
              "      <th>1646</th>\n",
              "      <th>1647</th>\n",
              "      <th>1648</th>\n",
              "      <th>1649</th>\n",
              "      <th>1650</th>\n",
              "      <th>1651</th>\n",
              "      <th>1652</th>\n",
              "      <th>1653</th>\n",
              "      <th>1654</th>\n",
              "      <th>1655</th>\n",
              "      <th>1656</th>\n",
              "      <th>1657</th>\n",
              "      <th>1658</th>\n",
              "      <th>1659</th>\n",
              "      <th>1660</th>\n",
              "      <th>1661</th>\n",
              "      <th>1662</th>\n",
              "      <th>1663</th>\n",
              "      <th>1664</th>\n",
              "      <th>1665</th>\n",
              "      <th>1666</th>\n",
              "      <th>1667</th>\n",
              "      <th>1668</th>\n",
              "      <th>1669</th>\n",
              "      <th>1670</th>\n",
              "      <th>1671</th>\n",
              "      <th>1672</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1683 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id    1    2    3    4    5  ...  1677  1678  1679  1680  1681  1682\n",
              "0          1  5.0  3.0  4.0  3.0  3.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "1          2  4.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "2          3  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "3          4  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "4          5  4.0  3.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "..       ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...\n",
              "938      939  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "939      940  0.0  0.0  0.0  2.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "940      941  5.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "941      942  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "942      943  0.0  5.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "\n",
              "[943 rows x 1683 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_d0HhUhGIS_",
        "colab_type": "code",
        "outputId": "ee8c1fd7-739c-4da9-df04-ab7500581130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "users_items_matrix_df.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 1683)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb1nV1UqGITF",
        "colab_type": "code",
        "outputId": "50b88015-0986-4b8b-8c90-65db7cae5830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "users_items_matrix_df.values.mean()*100"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.286534485898216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acmJ0Su_GITM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb546c4a-4573-42dd-f249-431edf4e33ea"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "def autoEncoder(X):\n",
        "    '''\n",
        "    Autoencoder for Collaborative Filter Model\n",
        "    '''\n",
        "\n",
        "    # Input\n",
        "    input_layer = Input(shape=(X.shape[1],), name='UserScore')\n",
        "    \n",
        "    # Encoder\n",
        "    # -----------------------------\n",
        "    enc = Dense(512, activation='selu', name='EncLayer1')(input_layer)\n",
        "\n",
        "    # Latent Space\n",
        "    # -----------------------------\n",
        "    lat_space = Dense(256, activation='selu', name='LatentSpace')(enc)\n",
        "    lat_space = Dropout(0.8, name='Dropout')(lat_space) # Dropout\n",
        "\n",
        "    # Decoder\n",
        "    # -----------------------------\n",
        "    dec = Dense(512, activation='selu', name='DecLayer1')(lat_space)\n",
        "\n",
        "    # Output\n",
        "    output_layer = Dense(X.shape[1], activation='linear', name='UserScorePred')(dec)\n",
        "\n",
        "    # this model maps an input to its reconstruction\n",
        "    model = Model(input_layer, output_layer)    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhlSCFrUGITQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input\n",
        "X = users_items_matrix_df.values\n",
        "y = users_items_matrix_df.values\n",
        "X=X[:,1:]\n",
        "y=y[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuEc7SlCIY0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "87a05799-2d34-4763-9c6d-867d36c492f1"
      },
      "source": [
        "y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 3., 4., ..., 0., 0., 0.],\n",
              "       [4., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [5., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 5., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQk4MQa_GITU",
        "colab_type": "code",
        "outputId": "084d9904-9e74-4053-ddbd-b34745d3d239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Build model\n",
        "model = autoEncoder(X)\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0001), loss='mse')\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "UserScore (InputLayer)       (None, 1682)              0         \n",
            "_________________________________________________________________\n",
            "EncLayer1 (Dense)            (None, 512)               861696    \n",
            "_________________________________________________________________\n",
            "LatentSpace (Dense)          (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "Dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "DecLayer1 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "UserScorePred (Dense)        (None, 1682)              862866    \n",
            "=================================================================\n",
            "Total params: 1,987,474\n",
            "Trainable params: 1,987,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OGn5nZQcGITX",
        "colab_type": "code",
        "outputId": "11965441-b5ee-46c8-8596-d0cbbfa9662d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start_time = time.time()\n",
        "hist = model.fit(x=X, y=y,\n",
        "                  epochs=50,\n",
        "                  batch_size=64,\n",
        "                  shuffle=True,\n",
        "                  validation_split=0.15)\n",
        "train_time = time.time() - start_time"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 801 samples, validate on 142 samples\n",
            "Epoch 1/50\n",
            "801/801 [==============================] - 1s 1ms/step - loss: 2.2029 - val_loss: 1.1477\n",
            "Epoch 2/50\n",
            "801/801 [==============================] - 1s 665us/step - loss: 1.8986 - val_loss: 1.0931\n",
            "Epoch 3/50\n",
            "801/801 [==============================] - 1s 679us/step - loss: 1.7193 - val_loss: 1.0445\n",
            "Epoch 4/50\n",
            "801/801 [==============================] - 1s 661us/step - loss: 1.6269 - val_loss: 0.9914\n",
            "Epoch 5/50\n",
            "801/801 [==============================] - 1s 666us/step - loss: 1.5231 - val_loss: 0.9319\n",
            "Epoch 6/50\n",
            "801/801 [==============================] - 1s 638us/step - loss: 1.4260 - val_loss: 0.8709\n",
            "Epoch 7/50\n",
            "801/801 [==============================] - 1s 654us/step - loss: 1.3421 - val_loss: 0.8187\n",
            "Epoch 8/50\n",
            "801/801 [==============================] - 1s 638us/step - loss: 1.2663 - val_loss: 0.7795\n",
            "Epoch 9/50\n",
            "801/801 [==============================] - 1s 662us/step - loss: 1.2085 - val_loss: 0.7493\n",
            "Epoch 10/50\n",
            "801/801 [==============================] - 1s 666us/step - loss: 1.1522 - val_loss: 0.7304\n",
            "Epoch 11/50\n",
            "801/801 [==============================] - 1s 655us/step - loss: 1.1070 - val_loss: 0.7156\n",
            "Epoch 12/50\n",
            "801/801 [==============================] - 1s 632us/step - loss: 1.0631 - val_loss: 0.7033\n",
            "Epoch 13/50\n",
            "801/801 [==============================] - 1s 650us/step - loss: 1.0297 - val_loss: 0.6934\n",
            "Epoch 14/50\n",
            "801/801 [==============================] - 0s 619us/step - loss: 1.0018 - val_loss: 0.6819\n",
            "Epoch 15/50\n",
            "801/801 [==============================] - 1s 673us/step - loss: 0.9745 - val_loss: 0.6736\n",
            "Epoch 16/50\n",
            "801/801 [==============================] - 1s 629us/step - loss: 0.9497 - val_loss: 0.6660\n",
            "Epoch 17/50\n",
            "801/801 [==============================] - 1s 639us/step - loss: 0.9264 - val_loss: 0.6581\n",
            "Epoch 18/50\n",
            "801/801 [==============================] - 1s 642us/step - loss: 0.9031 - val_loss: 0.6511\n",
            "Epoch 19/50\n",
            "801/801 [==============================] - 1s 635us/step - loss: 0.8830 - val_loss: 0.6430\n",
            "Epoch 20/50\n",
            "801/801 [==============================] - 1s 646us/step - loss: 0.8631 - val_loss: 0.6366\n",
            "Epoch 21/50\n",
            "801/801 [==============================] - 1s 655us/step - loss: 0.8499 - val_loss: 0.6295\n",
            "Epoch 22/50\n",
            "801/801 [==============================] - 1s 633us/step - loss: 0.8325 - val_loss: 0.6220\n",
            "Epoch 23/50\n",
            "801/801 [==============================] - 1s 633us/step - loss: 0.8145 - val_loss: 0.6163\n",
            "Epoch 24/50\n",
            "801/801 [==============================] - 1s 670us/step - loss: 0.8018 - val_loss: 0.6113\n",
            "Epoch 25/50\n",
            "801/801 [==============================] - 1s 663us/step - loss: 0.7890 - val_loss: 0.6045\n",
            "Epoch 26/50\n",
            "801/801 [==============================] - 1s 632us/step - loss: 0.7720 - val_loss: 0.6003\n",
            "Epoch 27/50\n",
            "801/801 [==============================] - 1s 663us/step - loss: 0.7639 - val_loss: 0.5947\n",
            "Epoch 28/50\n",
            "801/801 [==============================] - 1s 637us/step - loss: 0.7537 - val_loss: 0.5902\n",
            "Epoch 29/50\n",
            "801/801 [==============================] - 1s 666us/step - loss: 0.7429 - val_loss: 0.5845\n",
            "Epoch 30/50\n",
            "801/801 [==============================] - 1s 643us/step - loss: 0.7284 - val_loss: 0.5816\n",
            "Epoch 31/50\n",
            "801/801 [==============================] - 1s 633us/step - loss: 0.7228 - val_loss: 0.5774\n",
            "Epoch 32/50\n",
            "801/801 [==============================] - 1s 636us/step - loss: 0.7131 - val_loss: 0.5746\n",
            "Epoch 33/50\n",
            "801/801 [==============================] - 1s 653us/step - loss: 0.7046 - val_loss: 0.5709\n",
            "Epoch 34/50\n",
            "801/801 [==============================] - 1s 629us/step - loss: 0.6975 - val_loss: 0.5665\n",
            "Epoch 35/50\n",
            "801/801 [==============================] - 1s 671us/step - loss: 0.6909 - val_loss: 0.5633\n",
            "Epoch 36/50\n",
            "801/801 [==============================] - 1s 666us/step - loss: 0.6826 - val_loss: 0.5601\n",
            "Epoch 37/50\n",
            "801/801 [==============================] - 1s 645us/step - loss: 0.6761 - val_loss: 0.5568\n",
            "Epoch 38/50\n",
            "801/801 [==============================] - 1s 660us/step - loss: 0.6660 - val_loss: 0.5538\n",
            "Epoch 39/50\n",
            "801/801 [==============================] - 1s 654us/step - loss: 0.6622 - val_loss: 0.5521\n",
            "Epoch 40/50\n",
            "801/801 [==============================] - 1s 642us/step - loss: 0.6555 - val_loss: 0.5486\n",
            "Epoch 41/50\n",
            "801/801 [==============================] - 1s 659us/step - loss: 0.6517 - val_loss: 0.5468\n",
            "Epoch 42/50\n",
            "801/801 [==============================] - 1s 649us/step - loss: 0.6450 - val_loss: 0.5447\n",
            "Epoch 43/50\n",
            "801/801 [==============================] - 1s 637us/step - loss: 0.6433 - val_loss: 0.5430\n",
            "Epoch 44/50\n",
            "801/801 [==============================] - 1s 657us/step - loss: 0.6398 - val_loss: 0.5396\n",
            "Epoch 45/50\n",
            "801/801 [==============================] - 1s 648us/step - loss: 0.6317 - val_loss: 0.5393\n",
            "Epoch 46/50\n",
            "801/801 [==============================] - 1s 638us/step - loss: 0.6286 - val_loss: 0.5361\n",
            "Epoch 47/50\n",
            "801/801 [==============================] - 1s 643us/step - loss: 0.6238 - val_loss: 0.5335\n",
            "Epoch 48/50\n",
            "801/801 [==============================] - 1s 649us/step - loss: 0.6174 - val_loss: 0.5319\n",
            "Epoch 49/50\n",
            "801/801 [==============================] - 1s 636us/step - loss: 0.6149 - val_loss: 0.5304\n",
            "Epoch 50/50\n",
            "801/801 [==============================] - 1s 628us/step - loss: 0.6126 - val_loss: 0.5289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QJrgopQGITb",
        "colab_type": "code",
        "outputId": "2c3e20f1-3ce1-41dc-f7c3-f9cbc72369ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "def plot_hist(hist):\n",
        "    # summarize history for loss\n",
        "    fig, ax = plt.subplots()  # create figure & 1 axis\n",
        "\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    plt.plot(hist.history['loss'])\n",
        "    #plt.plot(hist.history['val_loss'])\n",
        "\n",
        "plot_hist(hist)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X0UVndfGITe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict new Matrix Interactions, set score zero on visualized movies\n",
        "start_time = time.time()\n",
        "new_matrix = model.predict(X) * (X == 0)\n",
        "test_time = time.time() - start_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7taan7sMGITg",
        "colab_type": "code",
        "outputId": "3f2693c7-3d11-4a17-8e83-bd6c756a58b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "new_matrix"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "        -1.20294295e-01,  2.44978935e-01, -1.42012015e-01],\n",
              "       [ 0.00000000e+00, -2.33413622e-01,  1.91593245e-01, ...,\n",
              "        -8.87693837e-02,  8.96334052e-02, -1.10671788e-01],\n",
              "       [-2.86364406e-02, -2.88148075e-01, -1.49551272e-01, ...,\n",
              "         2.23877318e-02, -2.21806392e-03,  1.17905121e-02],\n",
              "       ...,\n",
              "       [ 0.00000000e+00, -1.58464968e-01,  2.40285262e-01, ...,\n",
              "        -9.38374177e-03, -1.26850545e-01, -2.40249142e-01],\n",
              "       [ 1.63521183e+00,  9.88216698e-02, -6.88025579e-02, ...,\n",
              "         6.88060746e-02,  1.55108199e-01, -2.02771544e-01],\n",
              "       [ 3.46483159e+00,  0.00000000e+00,  9.30501461e-01, ...,\n",
              "        -1.76344901e-01,  2.92492449e-01, -2.00674031e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfT8Snrv29uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics_(data_true, data_pred,time_train, time_test):\n",
        "    mse=np.sqrt(mean_squared_error(data_true, data_pred))\n",
        "    mae=mean_absolute_error(data_true, data_pred)\n",
        "    r2=r2_score(data_true, data_pred)\n",
        "    ex_var=explained_variance_score(data_true, data_pred)\n",
        "    ndcg=ndcg_score(data_true, data_pred)\n",
        "    df=pd.DataFrame({\"RMSE\": mse, \"MAE\":mae, \"R2_score\":r2, \"explained variance\":ex_var, 'NDCG':ndcg,\n",
        "                     'train time':time_train, 'test time':time_test},index=[0])\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "163D0vKZGITi",
        "colab_type": "code",
        "outputId": "5b6a8a6a-0c34-4b3a-ae07-2e9a76bfad6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "metrics_(X, new_matrix,train_time, test_time)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R2_score</th>\n",
              "      <th>explained variance</th>\n",
              "      <th>NDCG</th>\n",
              "      <th>train time</th>\n",
              "      <th>test time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.002165</td>\n",
              "      <td>0.424605</td>\n",
              "      <td>-0.764325</td>\n",
              "      <td>-0.687154</td>\n",
              "      <td>0.405207</td>\n",
              "      <td>27.070047</td>\n",
              "      <td>0.201214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       RMSE       MAE  R2_score  ...      NDCG  train time  test time\n",
              "0  1.002165  0.424605 -0.764325  ...  0.405207   27.070047   0.201214\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6fb5937b-e3b0-40b9-c828-9efd4ed3f213",
        "id": "EWEuQogD2asU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(X, new_matrix)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-09a8ed91e551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efde19e6-d87a-45a0-c4fc-dbabf124bedb",
        "id": "HwFEtcBZ2asX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(X, new_matrix)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-898e686f5428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJmPUVZ73hE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}